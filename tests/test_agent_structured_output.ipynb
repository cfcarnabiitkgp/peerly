{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Agent Structured Output\n",
    "\n",
    "This notebook tests the Clarity and Rigor agents with LangChain's `with_structured_output()` to verify that:\n",
    "1. Agents return properly structured suggestions\n",
    "2. Each suggestion has separate `issue`, `explanation`, and `suggested_fix` fields\n",
    "3. The orchestrator properly combines suggestions from both agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/arnabbhattacharya/Desktop/Peerly-Demo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Model: gpt-4o-mini\n",
      "API Key loaded: Yes\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from app.agents.clarity_agent import ClarityAgent\n",
    "from app.agents.rigor_agent import RigorAgent\n",
    "from app.models.schemas import Section\n",
    "from app.config.settings import settings\n",
    "\n",
    "# Verify settings loaded\n",
    "print(f\"OpenAI Model: {settings.openai_model}\")\n",
    "print(f\"API Key loaded: {'Yes' if settings.openai_api_key else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sample: Technical Research Paper Section\n",
    "\n",
    "We'll use a sample introduction section that has both clarity and rigor issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Section:\n",
      "Title: Introduction\n",
      "Type: introduction\n",
      "Lines: 1-10\n",
      "\n",
      "Content:\n",
      "\n",
      "Machine learning has revolutionized various domains. Deep learning models achieve \n",
      "state-of-the-art results. Our novel algorithm improves upon existing approaches by \n",
      "utilizing advanced techniques. The convergence rate is faster than baseline methods.\n",
      "\n",
      "We conducted experiments on a dataset and observed significant improvements. The results \n",
      "demonstrate the superiority of our approach. Our method achieves better performance \n",
      "compared to traditional algorithms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a test section with intentional issues\n",
    "test_section = Section(\n",
    "    title=\"Introduction\",\n",
    "    content=\"\"\"\n",
    "Machine learning has revolutionized various domains. Deep learning models achieve \n",
    "state-of-the-art results. Our novel algorithm improves upon existing approaches by \n",
    "utilizing advanced techniques. The convergence rate is faster than baseline methods.\n",
    "\n",
    "We conducted experiments on a dataset and observed significant improvements. The results \n",
    "demonstrate the superiority of our approach. Our method achieves better performance \n",
    "compared to traditional algorithms.\n",
    "\"\"\",\n",
    "    section_type=\"introduction\",\n",
    "    line_start=1,\n",
    "    line_end=10\n",
    ")\n",
    "\n",
    "print(\"Test Section:\")\n",
    "print(f\"Title: {test_section.title}\")\n",
    "print(f\"Type: {test_section.section_type}\")\n",
    "print(f\"Lines: {test_section.line_start}-{test_section.line_end}\")\n",
    "print(f\"\\nContent:\\n{test_section.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Clarity Agent\n",
    "\n",
    "Test the Clarity Agent to see if it properly identifies clarity issues with structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Clarity Agent...\n",
      "\n",
      "Found 5 clarity suggestions\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize Clarity Agent\n",
    "clarity_agent = ClarityAgent()\n",
    "\n",
    "# Run clarity analysis\n",
    "print(\"Running Clarity Agent...\\n\")\n",
    "clarity_suggestions = await clarity_agent.review_section(test_section)\n",
    "\n",
    "print(f\"Found {len(clarity_suggestions)} clarity suggestions\\n\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuggestionItem(text=\"The phrase 'advanced techniques' is vague and lacks specificity.\", line=1, severity=<SeverityLevel.INFO: 'info'>, explanation='This statement does not clarify what these advanced techniques are, leaving readers unsure about the actual improvements made by the algorithm.', suggested_fix=\"Specify the advanced techniques used in the algorithm, such as 'utilizing convolutional neural networks and transfer learning'.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clarity_suggestions[0])\n",
    "clarity_suggestions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Clarity Suggestion 1\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The phrase 'advanced techniques' is vague and lacks specificity.\n",
      "\n",
      "üí° Explanation:\n",
      "   This statement does not clarify what these advanced techniques are, leaving readers unsure about the actual improvements made by the algorithm.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Specify the advanced techniques used in the algorithm, such as 'utilizing convolutional neural networks and transfer learning'.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìã Clarity Suggestion 2\n",
      "Severity: WARNING\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The statement 'The convergence rate is faster than baseline methods' is unclear without context.\n",
      "\n",
      "üí° Explanation:\n",
      "   It does not specify which baseline methods are being referenced, making it difficult for readers to understand the significance of the claim.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Clarify which baseline methods are being compared, for example, 'The convergence rate is faster than the standard gradient descent methods used in similar studies'.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìã Clarity Suggestion 3\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The phrase 'significant improvements' is subjective and lacks quantification.\n",
      "\n",
      "üí° Explanation:\n",
      "   Without specific metrics or data, this claim is ambiguous and does not provide a clear understanding of the improvements observed.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Include specific metrics or percentages that quantify the improvements, such as 'We observed a 20% increase in accuracy compared to previous models'.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìã Clarity Suggestion 4\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The statement 'Our method achieves better performance compared to traditional algorithms' is repetitive and lacks detail.\n",
      "\n",
      "üí° Explanation:\n",
      "   This statement reiterates the previous claim without providing new information or context, which can lead to redundancy and confusion.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Combine this statement with the previous one and provide specific performance metrics, such as 'Our method achieves a 15% higher accuracy than traditional algorithms in our experiments'.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìã Clarity Suggestion 5\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The section lacks context about the dataset used for experiments.\n",
      "\n",
      "üí° Explanation:\n",
      "   Readers may not understand the relevance or characteristics of the dataset, which is crucial for evaluating the results of the experiments.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Briefly describe the dataset, including its size, type, and relevance to the problem being addressed, such as 'We conducted experiments on a publicly available image classification dataset containing 10,000 labeled images'.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display clarity suggestions\n",
    "for i, suggestion in enumerate(clarity_suggestions, 1):\n",
    "    print(f\"\\nüìã Clarity Suggestion {i}\")\n",
    "    print(f\"Severity: {suggestion.severity.value.upper()}\")\n",
    "    print(f\"Line: {suggestion.line}\")\n",
    "    print(f\"\\nüî¥ Issue:\")\n",
    "    print(f\"   {suggestion.text}\")\n",
    "    print(f\"\\nüí° Explanation:\")\n",
    "    print(f\"   {suggestion.explanation}\")\n",
    "    print(f\"\\n‚úÖ Suggested Fix:\")\n",
    "    print(f\"   {suggestion.suggested_fix}\")\n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Rigor Agent\n",
    "\n",
    "Test the Rigor Agent to see if it properly identifies rigor issues with structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Rigor Agent...\n",
      "\n",
      "Found 5 rigor suggestions\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize Rigor Agent\n",
    "rigor_agent = RigorAgent()\n",
    "\n",
    "# Run rigor analysis\n",
    "print(\"Running Rigor Agent...\\n\")\n",
    "rigor_suggestions = await rigor_agent.review_section(test_section)\n",
    "\n",
    "print(f\"Found {len(rigor_suggestions)} rigor suggestions\\n\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Rigor Suggestion 1\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The section makes unverified claims about the superiority of the algorithm without providing supporting evidence or citations.\n",
      "\n",
      "üí° Explanation:\n",
      "   This undermines the credibility of the claims, as readers cannot assess the validity of the results or compare them to existing literature.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Include references to previous studies or datasets that support the claims of superiority, and provide quantitative results from experiments.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìä Rigor Suggestion 2\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The statement about the 'faster convergence rate' lacks mathematical justification or proof.\n",
      "\n",
      "üí° Explanation:\n",
      "   Without a formal proof or derivation, the claim may be seen as anecdotal and could mislead readers regarding the algorithm's performance.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Provide a mathematical analysis or proof that demonstrates the convergence rate of the algorithm compared to baseline methods.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìä Rigor Suggestion 3\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The experiments are described vaguely, lacking details on methodology, sample size, and controls.\n",
      "\n",
      "üí° Explanation:\n",
      "   This lack of detail makes it difficult for others to replicate the experiments or assess their validity, which is crucial for scientific rigor.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Include specific information about the dataset used, the experimental setup, sample sizes, and any control measures implemented during the experiments.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìä Rigor Suggestion 4\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   The section does not acknowledge any limitations of the proposed method or assumptions made during the study.\n",
      "\n",
      "üí° Explanation:\n",
      "   Failing to address limitations can lead to overgeneralization of the results and misinterpretation of the algorithm's applicability.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Explicitly state any assumptions made in the development of the algorithm and discuss potential limitations or scenarios where the algorithm may not perform as expected.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìä Rigor Suggestion 5\n",
      "Severity: INFO\n",
      "Line: 1\n",
      "\n",
      "üî¥ Issue:\n",
      "   There is no mention of statistical methods used to validate the significance of the results.\n",
      "\n",
      "üí° Explanation:\n",
      "   Without appropriate statistical analysis, the claims of 'significant improvements' are unsubstantiated and may not hold under scrutiny.\n",
      "\n",
      "‚úÖ Suggested Fix:\n",
      "   Incorporate statistical tests to validate the significance of the results, and report p-values or confidence intervals to support the claims made.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display rigor suggestions\n",
    "for i, suggestion in enumerate(rigor_suggestions, 1):\n",
    "    print(f\"\\nüìä Rigor Suggestion {i}\")\n",
    "    print(f\"Severity: {suggestion.severity.value.upper()}\")\n",
    "    print(f\"Line: {suggestion.line}\")\n",
    "    print(f\"\\nüî¥ Issue:\")\n",
    "    print(f\"   {suggestion.text}\")\n",
    "    print(f\"\\nüí° Explanation:\")\n",
    "    print(f\"   {suggestion.explanation}\")\n",
    "    print(f\"\\n‚úÖ Suggested Fix:\")\n",
    "    print(f\"   {suggestion.suggested_fix}\")\n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Verify Structured Fields\n",
    "\n",
    "Verify that all suggestions have properly populated fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification function\n",
    "def verify_suggestion_structure(suggestions, agent_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Verifying {agent_name} Suggestions Structure\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, suggestion in enumerate(suggestions, 1):\n",
    "        print(f\"Suggestion {i}:\")\n",
    "        \n",
    "        # Check text/issue\n",
    "        has_text = bool(suggestion.text and len(suggestion.text) > 0)\n",
    "        print(f\"  ‚úÖ Has issue: {has_text}\" if has_text else f\"  ‚ùå Missing issue\")\n",
    "        \n",
    "        # Check explanation\n",
    "        has_explanation = bool(suggestion.explanation and len(suggestion.explanation) > 0)\n",
    "        print(f\"  ‚úÖ Has explanation: {has_explanation}\" if has_explanation else f\"  ‚ùå Missing explanation\")\n",
    "        \n",
    "        # Check suggested_fix\n",
    "        has_fix = bool(suggestion.suggested_fix and len(suggestion.suggested_fix) > 0)\n",
    "        print(f\"  ‚úÖ Has suggested_fix: {has_fix}\" if has_fix else f\"  ‚ùå Missing suggested_fix\")\n",
    "        \n",
    "        # Check severity\n",
    "        has_severity = bool(suggestion.severity)\n",
    "        print(f\"  ‚úÖ Has severity: {suggestion.severity.value}\" if has_severity else f\"  ‚ùå Missing severity\")\n",
    "        \n",
    "        all_fields = has_text and has_explanation and has_fix and has_severity\n",
    "        status = \"‚úÖ PASS\" if all_fields else \"‚ùå FAIL\"\n",
    "        print(f\"\\n  Status: {status}\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    complete_count = sum(1 for s in suggestions if s.text and s.explanation and s.suggested_fix)\n",
    "    print(f\"\\nSummary: {complete_count}/{len(suggestions)} suggestions have all required fields\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Verifying Clarity Agent Suggestions Structure\n",
      "================================================================================\n",
      "\n",
      "Suggestion 1:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 2:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: warning\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 3:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 4:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 5:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "\n",
      "Summary: 5/5 suggestions have all required fields\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Clarity Agent suggestions\n",
    "verify_suggestion_structure(clarity_suggestions, \"Clarity Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Verifying Rigor Agent Suggestions Structure\n",
      "================================================================================\n",
      "\n",
      "Suggestion 1:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 2:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 3:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 4:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "Suggestion 5:\n",
      "  ‚úÖ Has issue: True\n",
      "  ‚úÖ Has explanation: True\n",
      "  ‚úÖ Has suggested_fix: True\n",
      "  ‚úÖ Has severity: info\n",
      "\n",
      "  Status: ‚úÖ PASS\n",
      "\n",
      "\n",
      "Summary: 5/5 suggestions have all required fields\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Rigor Agent suggestions\n",
    "verify_suggestion_structure(rigor_suggestions, \"Rigor Agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Test with RAG Guidelines\n",
    "\n",
    "Test agents with RAG-retrieved guidelines to ensure they incorporate domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with RAG guidelines...\n",
      "\n",
      "Clarity suggestions with RAG: 5\n",
      "\n",
      "First suggestion with guidelines:\n",
      "Issue: The statement 'Machine learning has revolutionized various domains' is vague and lacks specificity.\n",
      "Explanation: This claim does not specify which domains are affected or how they have been revolutionized, making it difficult for readers to grasp the significance of the statement.\n",
      "Fix: Specify the domains impacted by machine learning, such as healthcare, finance, or transportation, and provide examples of how it has changed those fields.\n"
     ]
    }
   ],
   "source": [
    "# Sample RAG guidelines\n",
    "sample_guidelines = \"\"\"\n",
    "Technical Writing Best Practices:\n",
    "- Always define technical terms when first introduced\n",
    "- Avoid vague claims like \"significant improvement\" - provide specific metrics\n",
    "- Include statistical significance tests (p-values) for experimental comparisons\n",
    "- State all assumptions explicitly before mathematical derivations\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing with RAG guidelines...\\n\")\n",
    "clarity_with_rag = await clarity_agent.review_section(test_section, guidelines=sample_guidelines)\n",
    "\n",
    "print(f\"Clarity suggestions with RAG: {len(clarity_with_rag)}\")\n",
    "print(\"\\nFirst suggestion with guidelines:\")\n",
    "if clarity_with_rag:\n",
    "    s = clarity_with_rag[0]\n",
    "    print(f\"Issue: {s.text}\")\n",
    "    print(f\"Explanation: {s.explanation}\")\n",
    "    print(f\"Fix: {s.suggested_fix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Integration Test with Full Workflow\n",
    "\n",
    "Test the full review workflow combining both agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running complete review workflow...\n",
      "\n",
      "Total Clarity Suggestions: 5\n",
      "Total Rigor Suggestions: 5\n",
      "Total Suggestions: 10\n",
      "\n",
      "Suggestions by severity:\n",
      "  info: 9\n",
      "  warning: 1\n"
     ]
    }
   ],
   "source": [
    "# Run both agents in parallel\n",
    "print(\"Running complete review workflow...\\n\")\n",
    "\n",
    "clarity_task = clarity_agent.review_section(test_section)\n",
    "rigor_task = rigor_agent.review_section(test_section)\n",
    "\n",
    "clarity_results, rigor_results = await asyncio.gather(clarity_task, rigor_task)\n",
    "\n",
    "print(f\"Total Clarity Suggestions: {len(clarity_results)}\")\n",
    "print(f\"Total Rigor Suggestions: {len(rigor_results)}\")\n",
    "print(f\"Total Suggestions: {len(clarity_results) + len(rigor_results)}\")\n",
    "\n",
    "# Group by severity\n",
    "all_suggestions = clarity_results + rigor_results\n",
    "severity_counts = {}\n",
    "for s in all_suggestions:\n",
    "    severity_counts[s.severity.value] = severity_counts.get(s.severity.value, 0) + 1\n",
    "\n",
    "print(f\"\\nSuggestions by severity:\")\n",
    "for severity, count in severity_counts.items():\n",
    "    print(f\"  {severity}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook verifies that:\n",
    "1. ‚úÖ Clarity Agent returns structured suggestions with separate fields\n",
    "2. ‚úÖ Rigor Agent returns structured suggestions with separate fields\n",
    "3. ‚úÖ All suggestions have `issue`, `explanation`, and `suggested_fix` populated\n",
    "4. ‚úÖ Severity levels are automatically determined\n",
    "5. ‚úÖ Agents can incorporate RAG guidelines\n",
    "6. ‚úÖ Both agents can run in parallel for efficient processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
